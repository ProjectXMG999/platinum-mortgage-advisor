# ğŸš€ PLAN OPTYMALIZACJI WYDAJNOÅšCI SYSTEMU

## ğŸ“Š Wyniki Benchmarku

**Åšredni czas przetwarzania: 64.4 sekundy** (cel: < 15s)
**Przekroczenie: +49.4 sekundy (330% wolniej niÅ¼ cel)**

### PodziaÅ‚ czasÃ³w:
- **ETAP 1 (Walidacja)**: ~31s (48%)
- **ETAP 2 (Ranking)**: ~33s (51%)
- **Inicjalizacja**: ~0.4s (1%)

---

## ğŸ¯ STRATEGIA OPTYMALIZACJI (CEL: < 15s)

### FAZA 1: QUICK WINS (Oczekiwane: -40s, do 24s) âš¡ PRIORYTET

#### 1.1 Zmiana modelu AI na szybszy
**Problem**: GPT-4o jest dokÅ‚adny ale wolny  
**RozwiÄ…zanie**: GPT-4o-mini (4-6x szybciej)
- Czas ETAP 1: 31s â†’ **6s** (oszczÄ™dnoÅ›Ä‡: ~25s)
- Czas ETAP 2: 33s â†’ **7s** (oszczÄ™dnoÅ›Ä‡: ~26s)

**Implementacja**:
```python
# src/config.py
DEPLOYMENT_NAME = "gpt-4o-mini"  # Zmiana z "gpt-4o"
```

**Ryzyko**: Nieznacznie niÅ¼sza jakoÅ›Ä‡ (testujemy)  
**Czas wdroÅ¼enia**: 5 minut

---

#### 1.2 Redukcja max_tokens
**Problem**: 16000 tokenÃ³w dla ETAP 1 to overkill  
**RozwiÄ…zanie**: Zmniejsz do 8000 (JSON dla 11 bankÃ³w ~4000-6000 tokenÃ³w)

**Implementacja**:
```python
# src/ai_client.py - line 527
max_tokens=8000  # Zmiana z 16000
```

**OszczÄ™dnoÅ›Ä‡**: ~3-5s (mniej tokenÃ³w = szybsza generacja)  
**Czas wdroÅ¼enia**: 1 minuta

---

#### 1.3 UproÅ›Ä‡ prompty
**Problem**: Prompty sÄ… bardzo szczegÃ³Å‚owe (dÅ‚ugie = wolne)  
**RozwiÄ…zanie**: 
- UsuÅ„ przykÅ‚ady z promptu walidacyjnego (~500 tokenÃ³w)
- SkrÃ³Ä‡ instrukcje (50% tekstu)

**OszczÄ™dnoÅ›Ä‡**: ~2-4s (mniej tokenÃ³w wejÅ›ciowych)  
**Czas wdroÅ¼enia**: 30 minut

---

### FAZA 2: ARCHITEKTURA (Oczekiwane: -10s, do 14s) ğŸ—ï¸ PRIORYTET

#### 2.1 Ranking tylko TOP 4 (zamiast wszystkich)
**Problem**: ETAP 2 rankuje wszystkie zakwalifikowane banki (nawet 10)  
**RozwiÄ…zanie**: Wybierz 4 najlepsze banki PO prostej heurystyce

**Implementacja**:
```python
def pre_filter_top_candidates(qualified_banks, validation_data):
    """Wybierz TOP 4-6 bankÃ³w przed rankingiem AI"""
    # Heurystyka: sortuj po liczbie speÅ‚nionych wymogÃ³w
    sorted_banks = sorted(
        qualified_banks, 
        key=lambda b: validation_data[b]["requirements_met"],
        reverse=True
    )
    return sorted_banks[:6]  # WeÅº TOP 6, AI zrankuje do TOP 4
```

**OszczÄ™dnoÅ›Ä‡**: ~10-15s (mniej tokenÃ³w output w ETAP 2)  
**Czas wdroÅ¼enia**: 1 godzina

---

#### 2.2 Asynchroniczne wywoÅ‚ania (jeÅ›li moÅ¼liwe)
**Problem**: ETAP 1 i ETAP 2 dziaÅ‚ajÄ… sekwencyjnie  
**RozwiÄ…zanie**: JeÅ›li API wspiera batch, rankuj TOP banki rÃ³wnolegle

**Implementacja** (zaawansowana):
```python
import asyncio

async def rank_bank_async(bank_name, context):
    # Rankuj 1 bank asynchronicznie
    pass

# Zamiast 1 wywoÅ‚ania dla 10 bankÃ³w â†’ 4 rÃ³wnolegÅ‚e dla TOP 4
```

**OszczÄ™dnoÅ›Ä‡**: ~5-10s (rÃ³wnolegÅ‚oÅ›Ä‡)  
**Czas wdroÅ¼enia**: 4 godziny (wymaga async refactor)

---

### FAZA 3: CACHE I OPTYMALIZACJE (Oczekiwane: -2s, do 12s) ğŸ’¾

#### 3.1 Cache powtarzajÄ…cych siÄ™ zapytaÅ„
**Problem**: Podobne profile generujÄ… podobne wyniki  
**RozwiÄ…zanie**: Redis/memory cache dla validation_prompt + query hash

**Implementacja**:
```python
import hashlib
from functools import lru_cache

@lru_cache(maxsize=100)
def get_cached_validation(query_hash):
    # Cache wynikÃ³w ETAP 1
    pass
```

**OszczÄ™dnoÅ›Ä‡**: ~30s dla powtÃ³rzeÅ„ (0s dla nowych)  
**Czas wdroÅ¼enia**: 2 godziny

---

#### 3.2 Prekompilowane prompty
**Problem**: Prompt tworzony przy kaÅ¼dym wywoÅ‚aniu  
**RozwiÄ…zanie**: Wczytaj raz przy inicjalizacji

**OszczÄ™dnoÅ›Ä‡**: ~0.5s  
**Czas wdroÅ¼enia**: 30 minut

---

## ğŸ“ˆ PRZEWIDYWANE WYNIKI PO OPTYMALIZACJI

| Faza | Zmiana | Czas ETAP 1 | Czas ETAP 2 | CAÅKOWITY | vs Cel |
|------|--------|-------------|-------------|-----------|--------|
| **Obecny** | - | 31s | 33s | **64s** | +49s âŒ |
| **Faza 1** | Szybszy model + tokens | 6s | 7s | **13s** | -2s âœ… |
| **Faza 2** | TOP 4 filter | 6s | 4s | **10s** | -5s âœ…âœ… |
| **Faza 3** | Cache | 3s* | 4s | **7s** | -8s âœ…âœ…âœ… |

*Cache dziaÅ‚a tylko dla powtÃ³rzeÅ„

---

## ğŸ› ï¸ PLAN WDROÅ»ENIA (REKOMENDOWANY)

### SPRINT 1 (1 godzina) - CRITICAL PATH
1. âœ… Zmiana modelu na gpt-4o-mini (5 min)
2. âœ… Redukcja max_tokens do 8000 (1 min)
3. âœ… Test wydajnoÅ›ci (10 min)
4. âœ… JeÅ›li < 20s â†’ przechodzimy do FAZA 2

### SPRINT 2 (2 godziny) - OPTIMIZATION
5. âœ… Ranking TOP 4 zamiast wszystkich (1h)
6. âœ… Uproszczenie promptÃ³w (30 min)
7. âœ… Test wydajnoÅ›ci (30 min)
8. âœ… JeÅ›li < 15s â†’ SUKCES! JeÅ›li nie â†’ FAZA 3

### SPRINT 3 (opcjonalny, 4 godziny) - POLISH
9. Cache dla powtarzajÄ…cych siÄ™ zapytaÅ„
10. Async wywoÅ‚ania (jeÅ›li Azure wspiera)
11. Monitoring wydajnoÅ›ci w Streamlit

---

## âš ï¸ RYZYKA

| Ryzyko | PrawdopodobieÅ„stwo | Mitygacja |
|--------|-------------------|-----------|
| GPT-4o-mini mniej dokÅ‚adny | Åšrednie | A/B test jakoÅ›ci wynikÃ³w |
| Redukcja max_tokens obcina JSON | Niskie | Walidacja parsowania |
| Cache daje stare wyniki | Niskie | TTL 1h, invalidacja po update bazy |

---

## ğŸ¯ METRYKI SUKCESU

- âœ… **Czas < 15s** dla 80% zapytaÅ„
- âœ… **Czas < 20s** dla 100% zapytaÅ„
- âœ… **JakoÅ›Ä‡ rankingu** > 90% zgodnoÅ›ci z GPT-4o (test A/B)
- âœ… **Zero bÅ‚Ä™dÃ³w** parsowania JSON

---

## ğŸ“ NASTÄ˜PNE KROKI

**TERAZ:**
1. ZatwierdÅº plan optymalizacji
2. Uruchom SPRINT 1 (zmiana modelu)
3. Zmierz wyniki

**Czy rozpoczynamy SPRINT 1?** ğŸš€
